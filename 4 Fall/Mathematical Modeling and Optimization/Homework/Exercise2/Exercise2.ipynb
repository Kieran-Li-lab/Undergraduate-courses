{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41ba6476",
   "metadata": {},
   "source": [
    "\n",
    "### Rosenbrock Minimization with Backtracking Line Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab5ba8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1) Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Backtracking parameters (Armijo)\n",
    "ALPHA_BAR = 1.0\n",
    "RHO       = 0.5\n",
    "C_ARMIJO  = 1e-4\n",
    "\n",
    "# Stopping\n",
    "TOL       = 1e-8\n",
    "MAX_SD_IT = 2000      # for steepest descent\n",
    "MAX_NT_IT = 200       # for Newton\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2844094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Rosenbrock function, gradient, Hessian\n",
    "def rosenbrock(x):\n",
    "    x1, x2 = x[0], x[1]\n",
    "    return 100.0*(x2 - x1**2)**2 + (1.0 - x1)**2\n",
    "\n",
    "def grad_rosenbrock(x):\n",
    "    x1, x2 = x[0], x[1]\n",
    "    df_dx1 = -400.0*x1*(x2 - x1**2) - 2.0*(1.0 - x1)\n",
    "    df_dx2 = 200.0*(x2 - x1**2)\n",
    "    return np.array([df_dx1, df_dx2])\n",
    "\n",
    "def hess_rosenbrock(x):\n",
    "    x1, x2 = x[0], x[1]\n",
    "    h11 = 1200.0*x1**2 - 400.0*x2 + 2.0\n",
    "    h12 = -400.0*x1\n",
    "    h22 = 200.0\n",
    "    return np.array([[h11, h12],[h12, h22]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d54c940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Backtracking line search (Armijo)\n",
    "def backtracking(f, grad, xk, pk, alpha_bar=ALPHA_BAR, rho=RHO, c=C_ARMIJO, max_backtracks=60):\n",
    "    alpha = alpha_bar\n",
    "    fk = f(xk)\n",
    "    gk = grad(xk)\n",
    "    slope0 = np.dot(gk, pk)\n",
    "    # Ensure descent (rarely needed for Newton if Hessian is PD)\n",
    "    if slope0 >= 0:\n",
    "        pk = -pk\n",
    "        slope0 = np.dot(gk, pk)\n",
    "    bt = 0\n",
    "    # Armijo condition\n",
    "    while f(xk + alpha*pk) > fk + c*alpha*slope0 and bt < max_backtracks:\n",
    "        alpha *= rho\n",
    "        bt += 1\n",
    "    return alpha, pk, bt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f215aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Steepest Descent and Newton's Method\n",
    "def steepest_descent(x0, max_iter=MAX_SD_IT, tol=TOL):\n",
    "    x = np.array(x0, dtype=float)\n",
    "    records = []\n",
    "    for k in range(max_iter):\n",
    "        g = grad_rosenbrock(x)\n",
    "        gn = np.linalg.norm(g)\n",
    "        fval = rosenbrock(x)\n",
    "        if gn <= tol:\n",
    "            records.append((k, x[0], x[1], fval, gn, np.nan, 0))\n",
    "            break\n",
    "        pk = -g\n",
    "        alpha, pk_adj, bt = backtracking(rosenbrock, grad_rosenbrock, x, pk)\n",
    "        x = x + alpha*pk_adj\n",
    "        records.append((k, x[0], x[1], rosenbrock(x), np.linalg.norm(grad_rosenbrock(x)), alpha, bt))\n",
    "    df = pd.DataFrame(records, columns=[\"iter\",\"x1\",\"x2\",\"f(x)\",\"||grad||\",\"alpha\",\"backtracks\"])\n",
    "    return df\n",
    "\n",
    "def newton_method(x0, max_iter=MAX_NT_IT, tol=TOL):\n",
    "    x = np.array(x0, dtype=float)\n",
    "    records = []\n",
    "    for k in range(max_iter):\n",
    "        g = grad_rosenbrock(x)\n",
    "        gn = np.linalg.norm(g)\n",
    "        fval = rosenbrock(x)\n",
    "        if gn <= tol:\n",
    "            records.append((k, x[0], x[1], fval, gn, np.nan, 0))\n",
    "            break\n",
    "        H = hess_rosenbrock(x)\n",
    "        # Solve H p = -g; fall back to least squares if singular/ill-conditioned\n",
    "        try:\n",
    "            pk = -np.linalg.solve(H, g)\n",
    "        except np.linalg.LinAlgError:\n",
    "            pk, *_ = np.linalg.lstsq(H, -g, rcond=None)\n",
    "        alpha, pk_adj, bt = backtracking(rosenbrock, grad_rosenbrock, x, pk)\n",
    "        x = x + alpha*pk_adj\n",
    "        records.append((k, x[0], x[1], rosenbrock(x), np.linalg.norm(grad_rosenbrock(x)), alpha, bt))\n",
    "    df = pd.DataFrame(records, columns=[\"iter\",\"x1\",\"x2\",\"f(x)\",\"||grad||\",\"alpha\",\"backtracks\"])\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68698780",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(      iter        x1        x2      f(x)   ||grad||     alpha  backtracks\n",
       " 0        0  1.087109  1.246875  0.430975  30.985565  0.000977          10\n",
       " 1        1  1.114571  1.234166  0.019689   4.168659  0.000977          10\n",
       " 2        2  1.110820  1.235749  0.012615   0.694695  0.000977          10\n",
       " 3        3  1.111397  1.235392  0.012413   0.143725  0.000977          10\n",
       " 4        4  1.111126  1.235318  0.012400   0.172884  0.001953           9\n",
       " ...    ...       ...       ...       ...        ...       ...         ...\n",
       " 1995  1995  1.005816  1.011669  0.000034   0.010117  0.001953           9\n",
       " 1996  1996  1.005796  1.011668  0.000034   0.009924  0.001953           9\n",
       " 1997  1997  1.005806  1.011651  0.000034   0.009738  0.001953           9\n",
       " 1998  1998  1.005788  1.011650  0.000034   0.009557  0.001953           9\n",
       " 1999  1999  1.005797  1.011634  0.000034   0.009382  0.001953           9\n",
       " \n",
       " [2000 rows x 7 columns],\n",
       "       iter        x1        x2      f(x)   ||grad||     alpha  backtracks\n",
       " 0        0 -0.989453  1.085938  5.101113  43.898521  0.000977          10\n",
       " 1        1 -1.064332  1.044172  5.047011  45.460144  0.001953           9\n",
       " 2        2 -1.023451  1.061483  4.114039   3.278977  0.000977          10\n",
       " 3        3 -1.026765  1.056002  4.108085   3.350914  0.001953           9\n",
       " 4        4 -1.020256  1.055316  4.102153   3.412960  0.001953           9\n",
       " ...    ...       ...       ...       ...        ...       ...         ...\n",
       " 1995  1995  0.988621  0.977289  0.000130   0.018979  0.001953           9\n",
       " 1996  1996  0.988602  0.977321  0.000130   0.017927  0.001953           9\n",
       " 1997  1997  0.988636  0.977326  0.000130   0.016983  0.001953           9\n",
       " 1998  1998  0.988622  0.977356  0.000129   0.016139  0.001953           9\n",
       " 1999  1999  0.988653  0.977362  0.000129   0.015386  0.001953           9\n",
       " \n",
       " [2000 rows x 7 columns],\n",
       "    iter        x1        x2          f(x)      ||grad||  alpha  backtracks\n",
       " 0     0  1.195918  1.430204  3.838403e-02  3.998201e-01    1.0           0\n",
       " 1     1  1.098284  1.196688  1.876234e-02  4.784866e+00    0.5           1\n",
       " 2     2  1.064488  1.131993  4.289183e-03  6.563523e-01    1.0           0\n",
       " 3     3  1.011992  1.021372  9.032733e-04  1.265832e+00    1.0           0\n",
       " 4     4  1.004261  1.008481  1.851409e-05  3.465826e-02    1.0           0\n",
       " 5     5  1.000050  1.000083  3.397039e-08  8.019780e-03    1.0           0\n",
       " 6     6  1.000000  1.000000  3.226676e-14  1.451948e-06    1.0           0\n",
       " 7     7  1.000000  1.000000  1.088287e-25  1.436039e-11    1.0           0\n",
       " 8     8  1.000000  1.000000  1.088287e-25  1.436039e-11    NaN           0,\n",
       "     iter        x1        x2          f(x)      ||grad||  alpha  backtracks\n",
       " 0      0 -1.175281  1.380674  4.731884e+00  4.639426e+00  1.000           0\n",
       " 1      1 -0.932981  0.811211  4.087399e+00  2.855008e+01  0.125           3\n",
       " 2      2 -0.782540  0.589736  3.228673e+00  1.157152e+01  1.000           0\n",
       " 3      3 -0.459997  0.107563  3.213898e+00  3.032589e+01  1.000           0\n",
       " 4      4 -0.393046  0.150002  1.942585e+00  3.604102e+00  1.000           0\n",
       " 5      5 -0.209412  0.006770  1.600194e+00  9.248418e+00  0.250           2\n",
       " 6      6 -0.065719 -0.016329  1.178390e+00  4.919801e+00  1.000           0\n",
       " 7      7  0.142043 -0.022989  9.224116e-01  8.664340e+00  1.000           0\n",
       " 8      8  0.231107  0.045478  5.974886e-01  1.778814e+00  1.000           0\n",
       " 9      9  0.379743  0.118146  4.526251e-01  5.877804e+00  0.500           1\n",
       " 10    10  0.479595  0.220041  2.807624e-01  2.176371e+00  1.000           0\n",
       " 11    11  0.653406  0.396729  2.113934e-01  9.401290e+00  1.000           0\n",
       " 12    12  0.702624  0.491258  8.901950e-02  4.920626e-01  1.000           0\n",
       " 13    13  0.802786  0.633221  5.153540e-02  3.924249e+00  0.500           1\n",
       " 14    14  0.863491  0.741931  1.999278e-02  1.242108e+00  1.000           0\n",
       " 15    15  0.942079  0.881336  7.169244e-03  2.533067e+00  1.000           0\n",
       " 16    16  0.967992  0.936337  1.069614e-03  2.375818e-01  1.000           0\n",
       " 17    17  0.996210  0.991639  7.776846e-05  3.482721e-01  1.000           0\n",
       " 18    18  0.999479  0.998948  2.824669e-07  3.874187e-03  1.000           0\n",
       " 19    19  0.999999  0.999998  8.517075e-12  1.187168e-04  1.000           0\n",
       " 20    20  1.000000  1.000000  3.743976e-21  4.473328e-10  1.000           0\n",
       " 21    21  1.000000  1.000000  3.743976e-21  4.473328e-10    NaN           0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5) Runs and results\n",
    "x0_easy = (1.2, 1.2)\n",
    "x0_hard = (-1.2, 1.0)\n",
    "\n",
    "sd_easy = steepest_descent(x0_easy)\n",
    "sd_hard = steepest_descent(x0_hard)\n",
    "\n",
    "nt_easy = newton_method(x0_easy)\n",
    "nt_hard = newton_method(x0_hard)\n",
    "\n",
    "# Display tables\n",
    "sd_easy, sd_hard, nt_easy, nt_hard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65f954e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: SD_x0_1p2_1p2.csv SD_x0_-1p2_1.csv NM_x0_1p2_1p2.csv NM_x0_-1p2_1.csv\n"
     ]
    }
   ],
   "source": [
    "# Save CSVs\n",
    "sd_easy.to_csv(\"SD_x0_1p2_1p2.csv\", index=False)\n",
    "sd_hard.to_csv(\"SD_x0_-1p2_1.csv\", index=False)\n",
    "nt_easy.to_csv(\"NM_x0_1p2_1p2.csv\", index=False)\n",
    "nt_hard.to_csv(\"NM_x0_-1p2_1.csv\", index=False)\n",
    "\n",
    "print(\"Saved:\", \"SD_x0_1p2_1p2.csv\", \"SD_x0_-1p2_1.csv\", \"NM_x0_1p2_1p2.csv\", \"NM_x0_-1p2_1.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
